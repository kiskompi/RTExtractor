#Bevezetés:
Az internet terjedésével egyre fontosabbá válik az a törekvés, hogy az ott fellelhető információ ne csak a felhasználók, hanem különböző szoftverek által is feldolgozható legyen. Ebből a célból jött létre a 2000-es évek elején a szemantikus web koncepciója, majd emiatt születtek meg a különböző tartalomkinyerési technológiák. A különböző célokra specializált tartalomkinyerő programok célja az, hogy a feladatuk szempontjából releváns információkat a lényegtelen információktól (ún. boilerplate) megtisztítva bányásszák ki a weboldalakból. Ilyen feladat lehet pl. a nyelvészeti célú felhasználás, illetve az információ kis méretű eszközökön jobban megjeleníthetővé tétele és a látássérültek számára készült képernyőolvasó programok által könnyebben feldolgozható formátumba történő alakítása.

A modern tartalomkinyerő rendszerek egyik legnagyobb kihívása, hogy képesek legyenek kibányászni az internet egyre nagyobb hányadát elfoglaló dinamikusan, futási időben generált weblapok releváns tartalmait. Ebbőn a szempontból a web rohamtempóban fejlődve maga mögött hagyta a webbányászatot, mivel annak csúcstechnológiát jelentő épviselői sem képesek ezen adatok teljes mértékű feldolgozására.

Jelen dolgozat célja, hogy röviden bemutassa a dinamikusan generált weblapok működésének alapjait, ismertesse atartalomkinyerés kihívásait ezen a területeén, és végül prezentáljon egy lehetséges megoldást a probléma kezelésére. Ilyen módon szűkíthető lenne a tartalomgenerálás- és kinyerés között utóbbi évtizedben kialakult technológiai rés.


#Részfeladatok:
- [ ] Elmenteni a felhasználó klikkelését, ami megmutatja, melyik link lenyomásával lehet az új adatot behozni. - Selenium WebIDE
- [ ] Képes legyen ezt az inputot megváltoztatni. - Selenium WebIDE szkriptfájljainak kezelése
- [ ] Az inputot (a DOM-elemet, ami aktiválja az adatlekérést) szerkeszthető formában tárolni. - Selenium WebIDE szkriptfájlja
- [ ] Az outputot olvasható formában tárolni. - mi legyen az output?
==============================================================================
- [ ] Differencciálja a betöltött HTML-adatokat és csak a különbséget menti el, így csökkentve a redundnciát.
- [ ] Monitorozza az oldalt, ajtomatikus változásokat keresve. Ha az addig láthatatlan, user által adott GET link megjelenik, rákattint (így nem kell az egész oldalt újratölteni).
- [ ] Gépi tanuló API, aminek segítségével az algoritmus felhasználói beavatkozás nélkül tanulhatja a weblap működését.

# Működés:

## Összefoglaló:
A program a Selenium WebIDE szkriptfájljaiból nyeri az inputot. Ezt lekezelve hajtja végre az utasításokat, absztrahálva, hogy ne csak a konkrét elemeket, hanem az ugyanabba az osztályba kerülő elemeket is kezelni tudja. Ehhez kell egy klasszifikátor.

A klasszifikátor működjön úgy, hogy megnézi a klikkelt elemek classait, majd a hasonlóan viselkedőkét (pl amelyik nem töltött be új URL-t) egy csoportba gyűjti a viselkedésének megfelelően. Emellett mindenképp megpróbál lemenni az oldal aljára, akkor is, ha nincs ilyen interakció. Az alulra görgetést viszont nem csinálja a végtelenségig, mert elfogy a memória.

1. A felhasználói interakció alapján megtanult csoportosítással a bejárt oldal SectionReveaLButton osztályú linkjeit vektorokba rakja, majd sorban meghívja őket.
2. Amikor a linkek elfogytak, az oldal aljára görget. 
    a. Ha nem töltődik be új tartalom: 3-as ponthoz.
    b. Ha betöltődik, akkor újra vektorba rendezi a inkeket, de csak azokat a SectionReveaLButton típusúakat járja be, amik az előző vektorban nem voltak benne. Ezután vissza a 2-es ponthoz (újra legörget). X (kb. 5) legörgetés után abbahagyja, mert túl nagy lenne a memóriaigény.
3.  Miután a legörgetést abbahagyhja, rámegy egy TraditionalHyperlinkButton típusú linkre, ami ugyanerre az URL-osztályra mutat (pl facebookról csak facebookra).

## Tehát:
1. Selenium WebIDE - ebbe jön a felhasználói input, elmenti a szkriptfájlját.
2. Klasszifikátor - a szkriptfájlban lévő DOM elemeket absztrahálja annyira, hogy a weboldal bármelyik hasonló típusú elemére felismerje a böngésző.
3. Végrehajtó - ami a szkriptet a Python Selenium API-val végrehajtatja.

## Lehetséges absztrakciók az interkcióra képes dolgokra:
### SectionRevealButton
    - pl. fb more comment, twitter new posts, Index Mindeközben új hír gombok, ez új szekciót nyit ki ugyanezen az oldalon
### LanguageSelectionButton:
    - ha a gomb megnyomásával a tartalom nem, de a tartalom nyelve megváltozik. pl. euronews
### OuterPageHyperlink:
    - sima link
### SamePageHyperlink:
    - ugyanennek az oldalnak egy másik aloldalára mutató link

## Speciális esetek, amikkel nem kel foglalkozni?
### PopUpSection
    - olyan, felhasználói interakciót igénylő oldalrész, ami blokkolja az oldal tartalmainak elérését. Kódszinten nem probléma, de a felhasználói interakció ami ezt kiiktatja értéktelen a crawlernek, ezért kiszűrendő. (interakció-boilerplate). lehet, hogy csak meg kéne mondani a felhasználóknak, hogy amikor ilyenre kattintsanak, addig állítsák le a felvételt, mert ronthatja a pontosságot/hatékonyságot/sebességet.
### ScrollDownLoader
    - ha lefele görget, akkor új tartalom jön be

Tehát: ismerje meg azokat a linkeket, melyek nem más URL-re irányítanak, hanem ezen az oldalon jelenítenek meg további tartalmakat. 
Ismerje fel azokat a lehetőségeket, melykor az oldal aljára görgetve új adatok töltődnek be. A felhasználói interakciókor a felugró div-ek még bezavarhatnak, de az automatizált crawling futásakor ez már nem szabad.

## Output:
Egy XML-be vagy YAML-ba mentse ki az tanulás eredményét, hogy újrafelhasználható legyen, kb. így:
'''XML
<SectionRevealButton>
    <webpage url="www.twitter.com">
        <group type = "SectionRevealButton">
            <class>CLASSNAME1</class>
            <class>CLASSNAME2</class> (azok a classnevek, amik indikálják a tanulás alapján, hogy ebbe a csoportba tartozik)
            <class>CLASSNAME3</class>
        </group>
        <group type = "LanguageSelectionButton">
            <class>CLASSNAME2</class> (azok a classnevek, amik indikálják a tanulás alapján, hogy ebbe a csoportba tartozik)
        </group>
        <group type = "ScrollDownLoader"></group> EZ ÜRES, A LÉTEZÉSE MÁR AZT JELENTI, HOGY HA LEGÖRGETEK, JÖN ÚJ ADAT
    </webpage>
    <webpage url="www.facebook.com">
    </webpage>
    <webpage url="www.euronews.com">
    </webpage>
    <webpage url="www.index.hu">
    </webpage>
</SectionRevealButton>
'''
Amit meg kell nézni: van-e bit.ly vagy goo.gl visszafejtő vagy valami hasonló.
Python libraryk:
    - scikit-learn
    - Pandas

# Implementációs fázisok
##Példa Usecase:
1. Gép valami gépitanulással eldönti, hogy mit kell kattintani és mit nem.
2. Ember hasonlóan...
3. Kettőt összehasonlítva mérjük a gépi tanulás "erejét" az adott feladatra...

##Példa Usecase2:
1. Gép eldönti, hogy hova kell kattintani...
2. Ember átnézi és neki nem tetszik, ekkor belejavít...

##Példa Usecase3:
1. Ember valami minta alapján generáltat valami utasítás listát, hogy ide kell kattintani. (Kvázi Első usecase 2.-pont csak itt az ember is automatizáltan csinálná a dolgokat)
2. A program eszerint működik.

##Továbbiak:

1. "Trollszűrő"
2. youtube commentek
3. euronews multiligual
4. kommentszekciók mutatása

#Kinda docu:
```python
def get_user_action():
    """This function captures the click of the user on the web page and stores it in a file."""
```
```python
def change_user_action():
    """This function changes the file by a new interaction, or manual rewriting.
    Can call get_user_action()"""
```
```python
def difference(old_page_source: list, new_page_source: list) -> str:
    """This function differentiates the two strings given as parameters.
```
```python
def get_refreshment(browser: splinter.Browser) -> list:
    """This function issues a new HTTP request by clicking on the
    "refresh" button saved by the get_refresh_button() function.
```
```python
def get_refresh_button():
    """This function saves the DOM elements of the page responsible
    for getting the new data, marked manually by the
    user. Calls get_user_action() or gets it from text input"""
```
```python
def run_extraction(urladdr: str):
    """The main function, containing the initial GET request, the
    main loop and the output"""
```